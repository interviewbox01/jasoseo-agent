import os
import json
import re
import yaml
from openai import OpenAI

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
import os
current_dir = os.path.dirname(os.path.abspath(__file__))
prompt_path = os.path.join(current_dir, 'prompt.yaml')
with open(prompt_path, 'r', encoding='utf-8') as f:
    prompt_data = yaml.safe_load(f)
    prompt_template = prompt_data['prompt']

def parse_industry_tags(content):
    """
    AI ì‘ë‹µì—ì„œ ì‚°ì—… íƒœê·¸ ë°°ì—´ì„ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        print(f"íŒŒì‹±í•  ì»¨í…ì¸  ê¸¸ì´: {len(content)}")
        print(f"íŒŒì‹±í•  ì»¨í…ì¸  ì²« 200ì: {repr(content[:200])}")
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        cleaned_content = content.strip()
        
        # 1. JSON ì½”ë“œ ë¸”ë¡ ì°¾ê¸° (```json ... ``` í˜•ì‹)
        json_patterns = [
            r'```json\s*(\[.*?\])\s*```',
            r'```\s*(\[.*?\])\s*```',
            r'```json\s*(.*?)\s*```',
            r'```\s*(.*?)\s*```'
        ]
        
        for pattern in json_patterns:
            json_match = re.search(pattern, cleaned_content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
                print(f"JSON ë¸”ë¡ ë°œê²¬: {repr(json_str[:100])}")
                
                # JSON ë¬¸ìì—´ ì •ë¦¬
                json_str = re.sub(r'\n\s*', ' ', json_str)
                json_str = re.sub(r',\s*]', ']', json_str)
                
                try:
                    parsed_json = json.loads(json_str)
                    if isinstance(parsed_json, list):
                        return parsed_json
                except json.JSONDecodeError as e:
                    print(f"JSON ë¸”ë¡ íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        # 2. ëŒ€ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë°°ì—´ ì°¾ê¸°
        array_patterns = [
            r'\[(.*?)\]'
        ]
        
        for pattern in array_patterns:
            array_match = re.search(pattern, cleaned_content, re.DOTALL)
            if array_match:
                array_content = array_match.group(1).strip()
                print(f"ë°°ì—´ ë‚´ìš© ë°œê²¬: {repr(array_content[:100])}")
                
                # ë°°ì—´ ë‚´ìš©ì—ì„œ ë¬¸ìì—´ ì¶”ì¶œ
                tags = []
                # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë¬¸ìì—´ë“¤ ì°¾ê¸°
                tag_matches = re.findall(r'"([^"]+)"', array_content)
                for tag in tag_matches:
                    if tag.strip():
                        tags.append(tag.strip())
                
                if tags:
                    return tags
        
        # 3. ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
        try:
            # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°
            if cleaned_content.startswith('```'):
                lines = cleaned_content.split('\n')
                start_idx = 1 if lines[0].startswith('```') else 0
                end_idx = len(lines)
                for i in range(len(lines)-1, -1, -1):
                    if lines[i].strip() == '```':
                        end_idx = i
                        break
                cleaned_content = '\n'.join(lines[start_idx:end_idx])
            
            cleaned_content = cleaned_content.strip()
            parsed_json = json.loads(cleaned_content)
            if isinstance(parsed_json, list):
                return parsed_json
        except json.JSONDecodeError as e:
            print(f"ì „ì²´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        # 4. ìµœí›„ì˜ ìˆ˜ë‹¨: íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ íƒœê·¸ ì¶”ì¶œ
        print("íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ íƒœê·¸ ì¶”ì¶œ ì‹œë„")
        tags = []
        
        # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ íƒœê·¸ ì°¾ê¸°
        patterns = [
            r'"([a-z-]+)"',  # ë”°ì˜´í‘œ ì•ˆì˜ íƒœê·¸ í˜•íƒœ
            r'([a-z-]+)',    # ë‹¨ìˆœ íƒœê·¸ í˜•íƒœ
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, cleaned_content)
            for match in matches:
                tag = match.strip()
                if len(tag) > 2 and '-' in tag and tag not in tags:
                    tags.append(tag)
                    if len(tags) >= 5:  # ìµœëŒ€ 5ê°œ
                        break
            if tags:
                break
        
        return tags[:5] if tags else []
        
    except Exception as e:
        print(f"íƒœê·¸ íŒŒì‹± ì „ì²´ ì˜¤ë¥˜: {e}")
        print(f"íŒŒì‹± ì‹¤íŒ¨í•œ ì»¨í…ì¸ : {repr(content)}")
        return []

def classify_industry(job_title, company_name):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì—…ì˜ ì‚°ì—…ì„ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        if not job_title or not company_name:
            return "ì§ë¬´ì™€ íšŒì‚¬ëª…ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.", []
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = prompt_template.format(
            job_title=job_title,
            company_name=company_name
        )
        
        # OpenAI Responses API í˜¸ì¶œ (Web Search Preview ì‚¬ìš©)
        response = client.responses.create(
            model="gpt-4o",
            tools=[{
                "type": "web_search_preview",
                "search_context_size": "high",
            }],
            input=f"ë‹¹ì‹ ì€ ê¸°ì—… ì‚°ì—… ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ê³  ì •í™•í•œ ì‚°ì—… íƒœê·¸ë¥¼ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.\n\n{prompt}"
        )
        
        content = response.output_text
        print(f"=== AI ì‘ë‹µ ì›ë³¸ ===")
        print(content)
        print(f"=== ì „ì²´ ì‘ë‹µ ê°ì²´ ===")
        print(response)
        
        # ì›¹ ê²€ìƒ‰ ì°¸ê³  ë§í¬ ì¶œë ¥
        if hasattr(response, 'web_search_results') and response.web_search_results:
            print(f"=== ì°¸ê³ í•œ ì›¹ ê²€ìƒ‰ ë§í¬ ===")
            for i, result in enumerate(response.web_search_results, 1):
                if hasattr(result, 'url'):
                    print(f"{i}. {result.url}")
                elif hasattr(result, 'link'):
                    print(f"{i}. {result.link}")
        
        print(f"=== AI ì‘ë‹µ ë ===")
        
        tags = parse_industry_tags(content)
        
        if not tags:
            return "ì‚°ì—… ë¶„ë¥˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
        
        # íƒœê·¸ëª… ë§¤í•‘ (í‘œì‹œìš©)
        tag_mapping = {
            "platform-portal": "í”Œë«í¼/í¬í„¸",
            "e-commerce": "ì´ì»¤ë¨¸ìŠ¤",
            "game": "ê²Œì„",
            "it-solution-si": "ITì†”ë£¨ì…˜/SI",
            "o2o-vertical": "O2O/ë²„í‹°ì»¬",
            "ai-data": "AI/ë°ì´í„°",
            "cloud-saas": "í´ë¼ìš°ë“œ/SaaS",
            "fintech": "í•€í…Œí¬",
            "semiconductor": "ë°˜ë„ì²´",
            "electronics-home": "ê°€ì „/ì „ìì œí’ˆ",
            "automotive-mobility": "ìë™ì°¨/ëª¨ë¹Œë¦¬í‹°",
            "battery": "2ì°¨ì „ì§€",
            "display": "ë””ìŠ¤í”Œë ˆì´",
            "heavy-industry-shipbuilding": "ì¤‘ê³µì—…/ì¡°ì„ ",
            "steel-metal": "ì² ê°•/ê¸ˆì†",
            "bank": "ì€í–‰",
            "securities": "ì¦ê¶Œ",
            "insurance": "ë³´í—˜",
            "card": "ì¹´ë“œ",
            "asset-management": "ìì‚°ìš´ìš©",
            "dept-store-mart": "ë°±í™”ì /ë§ˆíŠ¸",
            "convenience-store": "í¸ì˜ì ",
            "fmcg-beverage": "FMCG/ì‹ìŒë£Œ",
            "fashion-beauty": "íŒ¨ì…˜/ë·°í‹°",
            "duty-free": "ë©´ì„¸ì ",
            "pharma-new-drug": "ì œì•½/ì‹ ì•½ê°œë°œ",
            "bio-cmo": "ë°”ì´ì˜¤/CMO",
            "medical-device": "ì˜ë£Œê¸°ê¸°",
            "digital-healthcare": "ë””ì§€í„¸í—¬ìŠ¤ì¼€ì–´",
            "entertainment": "ì—”í„°í…Œì¸ë¨¼íŠ¸",
            "contents-video": "ì½˜í…ì¸ /ì˜ìƒì œì‘",
            "ad-agency": "ê´‘ê³ ëŒ€í–‰ì‚¬",
            "webtoon-webnovel": "ì›¹íˆ°/ì›¹ì†Œì„¤",
            "broadcasting-press": "ë°©ì†¡/ì–¸ë¡ ",
            "construction-engineering": "ê±´ì„¤/ì—”ì§€ë‹ˆì–´ë§",
            "realestate-development": "ë¶€ë™ì‚°ê°œë°œ",
            "plant": "í”ŒëœíŠ¸",
            "interior": "ì¸í…Œë¦¬ì–´",
            "public-soc": "SOC (ê³µí•­,ë„ë¡œ,ì² ë„)",
            "public-energy": "ì—ë„ˆì§€ ê³µê¸°ì—…",
            "public-finance": "ê¸ˆìœµ ê³µê¸°ì—…",
            "public-admin": "ì¼ë°˜í–‰ì •",
            "mpe-semiconductor": "ë°˜ë„ì²´ ì†Œë¶€ì¥",
            "mpe-display": "ë””ìŠ¤í”Œë ˆì´ ì†Œë¶€ì¥",
            "mpe-battery": "2ì°¨ì „ì§€ ì†Œë¶€ì¥",
            "auto-parts": "ìë™ì°¨ ë¶€í’ˆ",
            "chemical-materials": "í™”í•™/ì†Œì¬",
            "hotel": "í˜¸í…”",
            "travel-agency": "ì—¬í–‰ì‚¬",
            "airline": "í•­ê³µì‚¬",
            "leisure-resort": "ë ˆì €/ë¦¬ì¡°íŠ¸",
            "consulting": "ì»¨ì„¤íŒ…",
            "accounting-tax": "íšŒê³„/ì„¸ë¬´",
            "law-firm": "ë²•ë¥  (ë¡œíŒ)",
            "market-research": "ë¦¬ì„œì¹˜",
            "logistics-delivery": "ë¬¼ë¥˜/íƒë°°",
            "shipping": "í•´ìš´",
            "forwarding": "í¬ì›Œë”©",
            "land-transport": "ìœ¡ìƒìš´ì†¡",
            "edutech": "ì—ë“€í…Œí¬",
            "private-academy": "ì…ì‹œ/ë³´ìŠµí•™ì›",
            "edu-publishing": "êµìœ¡ì¶œíŒ",
            "language-edu": "ì™¸êµ­ì–´êµìœ¡",
            "ngo-npo": "NGO/NPO",
            "social-enterprise": "ì‚¬íšŒì ê¸°ì—…",
            "foundation": "ì¬ë‹¨"
        }
        
        # ê²°ê³¼ í¬ë§·íŒ…
        result = f"""## ğŸ¢ {company_name} - {job_title} ì‚°ì—… ë¶„ë¥˜ ê²°ê³¼

### ğŸ·ï¸ **ë¶„ë¥˜ëœ ì‚°ì—… íƒœê·¸**

"""
        for i, tag in enumerate(tags, 1):
            tag_name = tag_mapping.get(tag, tag)
            result += f"**{i}.** #{tag_name} (`{tag}`)\n\n"
        
        result += f"""
---
**ğŸ“ ì…ë ¥ ì •ë³´:**
- íšŒì‚¬: {company_name}
- ì§ë¬´: {job_title}
- ë¶„ë¥˜ëœ íƒœê·¸ ìˆ˜: {len(tags)}ê°œ

*ë³¸ ë¶„ë¥˜ëŠ” AIê°€ ìˆ˜í–‰í•œ ê²ƒìœ¼ë¡œ, ì‹¤ì œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.*
"""
        
        return result, tags
        
    except Exception as e:
        error_msg = f"""## âŒ ì˜¤ë¥˜ ë°œìƒ

ì‚°ì—… ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ë‚´ìš©:** {str(e)}

ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
"""
        return error_msg, [] 